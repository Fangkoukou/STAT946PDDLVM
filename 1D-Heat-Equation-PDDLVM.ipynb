{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774e5b87-6012-47da-9c52-f362de7cc4c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pddlvm\\Lib\\site-packages\\torch\\__init__.py:274\u001b[0m\n\u001b[0;32m    270\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    272\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 274\u001b[0m     _load_dll_libraries()\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pddlvm\\Lib\\site-packages\\torch\\__init__.py:250\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    248\u001b[0m is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[1;32m--> 250\u001b[0m     res \u001b[38;5;241m=\u001b[39m kernel32\u001b[38;5;241m.\u001b[39mLoadLibraryExW(dll, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0x00001100\u001b[39m)\n\u001b[0;32m    251\u001b[0m     last_error \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mget_last_error()\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m126\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.distributions as D\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau, StepLR\n",
    "# Set computation device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a912012-6309-4f84-85d0-4db3794ed8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input:\n",
    "    \"\"\"Handles generation of input coordinates for different constraint types\n",
    "    \n",
    "    Attributes:\n",
    "        x (np.array): Spatial coordinates array\n",
    "        t (np.array): Temporal coordinates array\n",
    "        \n",
    "    Methods:\n",
    "        get_ic: Initial condition coordinates (t=0)\n",
    "        get_bc: Boundary condition coordinates (x=0,L)\n",
    "        get_colloc: Collocation points for PDE residual calculation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, x, t):\n",
    "        \"\"\"Initialize spatial and temporal domains\"\"\"\n",
    "        self.x = x\n",
    "        self.t = t\n",
    "        \n",
    "    def get_ic(self):\n",
    "        \"\"\"Generate initial condition coordinates (t=0 for all x)\n",
    "        \n",
    "        Returns:\n",
    "            X (torch.Tensor): Spatial coordinates with grad enabled\n",
    "            T (torch.Tensor): Zero-initialized temporal coordinates\n",
    "        \"\"\"\n",
    "        X = torch.from_numpy(self.x).float().to(device)\n",
    "        T = torch.zeros_like(X).to(device)\n",
    "        X.requires_grad_()\n",
    "        T.requires_grad_()\n",
    "        return X, T\n",
    "\n",
    "    def get_bc(self):\n",
    "        \"\"\"Generate boundary condition coordinates (x=0,L for all t>0)\n",
    "        \n",
    "        Returns:\n",
    "            X (torch.Tensor): Repeated boundary coordinates\n",
    "            T (torch.Tensor): Temporal coordinates excluding t=0\n",
    "        \"\"\"\n",
    "        X = self.x[[0,-1]].repeat(len(self.t)-1)\n",
    "        T = np.concatenate([self.t[1:], self.t[1:]])  # Fixed np.concat -> np.concatenate\n",
    "        X = torch.from_numpy(X).float().to(device)\n",
    "        T = torch.from_numpy(T).float().to(device)\n",
    "        X.requires_grad_()\n",
    "        T.requires_grad_()\n",
    "        return X, T\n",
    "    \n",
    "    def get_colloc(self):\n",
    "        \"\"\"Generate collocation points for PDE residual calculation\n",
    "        \n",
    "        Returns:\n",
    "            X (torch.Tensor): Flattened spatial coordinates (interior points)\n",
    "            T (torch.Tensor): Flattened temporal coordinates (t>0)\n",
    "        \"\"\"\n",
    "        x_colloc = self.x[1:-1]\n",
    "        t_colloc = self.t[1:]\n",
    "        X,T = np.meshgrid(x_colloc,t_colloc,indexing='ij')\n",
    "        X = torch.from_numpy(X.ravel()).float().to(device)\n",
    "        T = torch.from_numpy(T.ravel()).float().to(device)\n",
    "        X.requires_grad_()\n",
    "        T.requires_grad_()\n",
    "        return X, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110bcec-526b-4f5f-83ed-f980d1f23120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlphaNet(nn.Module):\n",
    "    \"\"\"Probabilistic neural network for predicting PDE solution distribution\n",
    "    \n",
    "    Architecture:\n",
    "        - Multiple hidden layers with SiLU activation\n",
    "        - Dual output heads for mean and log-variance\n",
    "        - Incorporates spatial, temporal, and parameter inputs (X,T,g,k)\n",
    "    \n",
    "    Args:\n",
    "        hidden_features (list): List of neurons per hidden layer\n",
    "        in_features (int): Number of input features (default=4: X,T,g,k)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_features, in_features=4):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        \n",
    "        # Construct hidden layer architecture\n",
    "        prev_features = in_features\n",
    "        for features in hidden_features:\n",
    "            self.hidden_layers.append(nn.Linear(prev_features, features))\n",
    "            prev_features = features\n",
    "        \n",
    "        # Output layers for distribution parameters\n",
    "        self.mu_layer = nn.Linear(prev_features, 1)  # Mean prediction\n",
    "        self.logsig_layer = nn.Linear(prev_features, 1)  # Log-variance prediction\n",
    "\n",
    "    def forward(self, X, T, g, k):\n",
    "        \"\"\"Forward pass with reparameterized features\n",
    "        \n",
    "        Returns:\n",
    "            mu (torch.Tensor): Predicted mean values\n",
    "            logsig (torch.Tensor): Log-standard deviation (softplus-regularized)\n",
    "        \"\"\"\n",
    "        G = g * torch.ones_like(X)\n",
    "        K = k * torch.ones_like(X)\n",
    "        inp = torch.stack([X,T,G,K], dim=1)\n",
    "        for layer in self.hidden_layers:\n",
    "            inp = F.silu(layer(inp))\n",
    "        mu = self.mu_layer(inp).squeeze(-1)\n",
    "        logsig = F.softplus(self.logsig_layer(inp)).squeeze(-1) + 1e-6  # Ensure positivity\n",
    "        \n",
    "        return mu, logsig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9089b13b-878e-4b91-9a9e-eaf9c1247c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_u(mu, sig):\n",
    "    \"\"\"Reparameterization trick for sampling from distribution\n",
    "    \n",
    "    Args:\n",
    "        mu (torch.Tensor): Predicted mean values\n",
    "        sig (torch.Tensor): Predicted standard deviation values\n",
    "    \n",
    "    Returns:\n",
    "        u (torch.Tensor): Sampled solution values\n",
    "    \"\"\"\n",
    "    epsilon = torch.randn_like(mu)\n",
    "    return mu + sig * epsilon\n",
    "\n",
    "def get_dudx(u, X, create_graph=True):\n",
    "    \"\"\"Compute first derivative using automatic differentiation\n",
    "    \n",
    "    Args:\n",
    "        u (torch.Tensor): Solution values\n",
    "        X (torch.Tensor): Input coordinates\n",
    "        create_graph (bool): Enable higher-order derivative tracking\n",
    "    \n",
    "    Returns:\n",
    "        grad (torch.Tensor): du/dX values\n",
    "    \"\"\"\n",
    "    return torch.autograd.grad(u, X, torch.ones_like(u), \n",
    "                             retain_graph=True, create_graph=create_graph)[0]\n",
    "\n",
    "def get_residual(u, X, T, g, k):\n",
    "    \"\"\"Compute PDE residual: ∂u/∂t - (1/g)∇·(η(u)∇u)\n",
    "    \n",
    "    Where η(u) = |(k²u + 1)/k|\n",
    "    \n",
    "    Args:\n",
    "        u (torch.Tensor): Predicted solution values\n",
    "        X (torch.Tensor): Spatial coordinates\n",
    "        T (torch.Tensor): Temporal coordinates\n",
    "        g (float): PDE parameter\n",
    "        k (float): PDE parameter\n",
    "    \n",
    "    Returns:\n",
    "        residual (torch.Tensor): PDE residual values\n",
    "    \"\"\"\n",
    "    ut = get_dudx(u, T)  # Time derivative\n",
    "    ux = get_dudx(u, X)  # Spatial derivative\n",
    "    eta = torch.abs((u * k**2 + 1)/k)  # Nonlinear coefficient\n",
    "    return ut - (1/g) * get_dudx(eta * ux, X)  # PDE residual\n",
    "\n",
    "def loss_ic(model, X, T, g, k, ic):\n",
    "    \"\"\"Initial condition loss: Negative log probability\n",
    "    \n",
    "    Combines:\n",
    "        - Likelihood of samples under predicted distribution\n",
    "        - Constraint matching to initial condition\n",
    "    \n",
    "    Args:\n",
    "        model (AlphaNet): Trained network\n",
    "        X (torch.Tensor): Spatial coordinates\n",
    "        T (torch.Tensor): Temporal coordinates (zeros)\n",
    "        g (float): PDE parameter\n",
    "        k (float): PDE parameter\n",
    "        ic (torch.Tensor): Initial condition values\n",
    "    \n",
    "    Returns:\n",
    "        loss (torch.Tensor): Negative log probability\n",
    "    \"\"\"\n",
    "    mu, sig = model(X, T, g, k)\n",
    "    u = get_u(mu, sig)\n",
    "    \n",
    "    u_dist = D.Normal(mu, sig)\n",
    "    l1 = u_dist.log_prob(u)  # Likelihood term\n",
    "    \n",
    "    r_dist = D.Normal(u-ic, 0.001*torch.ones_like(u))\n",
    "    l2 = r_dist.log_prob(torch.zeros_like(u))  # Constraint term\n",
    "    \n",
    "    return l1 - l2\n",
    "\n",
    "def loss_bc(model, X, T, g, k, bc):\n",
    "    \"\"\"Boundary condition loss (similar structure to loss_ic)\n",
    "    \n",
    "    Args:\n",
    "        bc (torch.Tensor): Boundary condition values\n",
    "    \"\"\"\n",
    "    mu, sig = model(X, T, g, k)\n",
    "    u = get_u(mu, sig)\n",
    "    \n",
    "    u_dist = D.Normal(mu, sig)\n",
    "    l1 = u_dist.log_prob(u)\n",
    "    \n",
    "    r_dist = D.Normal(u-bc, 0.001*torch.ones_like(u))\n",
    "    l2 = r_dist.log_prob(torch.zeros_like(u))\n",
    "    \n",
    "    return l1 - l2\n",
    "\n",
    "def loss_colloc(model, X, T, g, k):\n",
    "    \"\"\"Physics-informed loss at collocation points\n",
    "    \n",
    "    Returns:\n",
    "        loss (torch.Tensor): Combined negative log probability\n",
    "        residual (torch.Tensor): PDE residual values\n",
    "    \"\"\"\n",
    "    mu, sig = model(X, T, g, k)\n",
    "    u = get_u(mu, sig)\n",
    "\n",
    "    u_dist = D.Normal(mu, sig)\n",
    "    l1 = u_dist.log_prob(u)\n",
    "\n",
    "    residual = get_residual(u, X, T, g, k)\n",
    "    r_dist = D.Normal(residual, 0.001*torch.ones_like(residual))\n",
    "    l2 = r_dist.log_prob(torch.zeros_like(residual))\n",
    "\n",
    "    return l1 - l2, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9673ab-05f3-4f1f-844f-247fe17c06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up initial conditions\n",
    "g = 2  # model parameter (gamma)\n",
    "k = 3\n",
    "N = 2**8\n",
    "x = np.linspace(0, 2*np.pi, N)  # x: discretization of interval [0,16pi] into 2^7 elements\n",
    "t = np.linspace(0,10,600)\n",
    "inp = Input(x,t)\n",
    "Xic, Tic = inp.get_ic()\n",
    "ic = (torch.sin(Xic) + 1).detach()\n",
    "Xbc, Tbc = inp.get_bc()\n",
    "bc = torch.ones_like(Xbc)\n",
    "Xcolloc, Tcolloc = inp.get_colloc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbbea9e-4171-4765-8982-4eb6687423e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = AlphaNet([128,128,128,64]).to(device)\n",
    "#alpha.load_state_dict(torch.load(\"alpha-0.5.pth\",map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e159f-f775-4947-9de6-54df011bf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer_adamw = torch.optim.AdamW(alpha.parameters(), lr=lr)\n",
    "optimizer = optimizer_adamw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69eb8e-b665-40e1-a87c-98f33b9d30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 7000\n",
    "epoch_time = 0\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.perf_counter()\n",
    "    alpha.train()\n",
    "    # compute losses\n",
    "    l1 = torch.mean(loss_ic(alpha,Xic,Tic,g,k,ic)) # initial condition loss\n",
    "    l2 = torch.mean(loss_bc(alpha,Xbc,Tbc,g,k,bc)) # boundary condition loss\n",
    "    l3,l4 = loss_colloc(alpha,Xcolloc,Tcolloc,g,k) # collocation and residual\n",
    "    l3 = torch.mean(l3) # collocation loss\n",
    "    l4 = F.mse_loss(l4,torch.zeros_like(l4)) # residual loss\n",
    "    loss = (1*l1+1*l2+1*l3)\n",
    "    optimizer.zero_grad()\n",
    "    # backward step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    epoch_time += time.perf_counter() - epoch_start \n",
    "    if epoch%100 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f} | current_lr = {optimizer.param_groups[0]['lr']} | Time: {epoch_time:.2f} seconds\")\n",
    "        print(f\"L1: {l1}| L2: {l2}| L3: {l3} | L4: {l4}\")\n",
    "        epoch_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547105d7-2675-486f-9932-6136f70d5ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf = Xic\n",
    "Tf = 3 * torch.ones_like(Xf)\n",
    "result, _ = alpha(Xf,Tf,g,k)\n",
    "result_cpu = result.cpu().detach()\n",
    "result_np = result_cpu.numpy()\n",
    "print(result_np)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(result_cpu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43691bb-b5a4-49eb-ae5a-b4f6ec197217",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(alpha.state_dict(),\"alpha-0.5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c8ce52-d2b9-41a3-abfa-c2a076ecb4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pddlvm)",
   "language": "python",
   "name": "pddlvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
